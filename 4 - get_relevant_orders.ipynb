{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import spacy\n",
    "import pickle\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "from collections import defaultdict\n",
    "from itertools import chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "processed_queries = pd.read_csv('data\\\\processed_queries.csv')\n",
    "processed_orders = pd.read_csv('data\\\\processed_orders.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>query</th>\n",
       "      <th>named_entities</th>\n",
       "      <th>summary</th>\n",
       "      <th>chunks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Landlord said he's moving in on Friday</td>\n",
       "      <td>My girlfriend has been renting an apartment wi...</td>\n",
       "      <td>[Landlord, Friday, 1 month, This morning, 175,...</td>\n",
       "      <td>My girlfriend has been renting an apartment wi...</td>\n",
       "      <td>[Landlord, he, Friday, My girlfriend, an apart...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Advice and vent on landlord invading privacy</td>\n",
       "      <td>Yesterday, my missus and I were freshly post c...</td>\n",
       "      <td>[Yesterday, about 3pm, n’t]</td>\n",
       "      <td>Yesterday, my missus and I were freshly post c...</td>\n",
       "      <td>[Advice, vent, landlord invading privacy, my m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Landlord keeps coming onto property</td>\n",
       "      <td>We're in a rental we're there is a locked shed...</td>\n",
       "      <td>[Landlord, English, 3 years]</td>\n",
       "      <td>We're in a rental we're there is a locked shed...</td>\n",
       "      <td>[Landlord, property, We, a rental, we, a locke...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Landlords have put a local candidate election ...</td>\n",
       "      <td>As per title I'm not particularly happy about ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>I'm not particularly happy about having my lan...</td>\n",
       "      <td>[Landlords, a local candidate election sign, m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Can a Landlord Complain About Beds Not Being M...</td>\n",
       "      <td>I feel a little harassed. Should we make a com...</td>\n",
       "      <td>[three, our thirties, every two weeks, a day, ...</td>\n",
       "      <td>Three males all in their thirties had a flat i...</td>\n",
       "      <td>[a Landlord Complain, Beds, I, we, a complaint...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0             Landlord said he's moving in on Friday   \n",
       "1       Advice and vent on landlord invading privacy   \n",
       "2                Landlord keeps coming onto property   \n",
       "3  Landlords have put a local candidate election ...   \n",
       "4  Can a Landlord Complain About Beds Not Being M...   \n",
       "\n",
       "                                               query  \\\n",
       "0  My girlfriend has been renting an apartment wi...   \n",
       "1  Yesterday, my missus and I were freshly post c...   \n",
       "2  We're in a rental we're there is a locked shed...   \n",
       "3  As per title I'm not particularly happy about ...   \n",
       "4  I feel a little harassed. Should we make a com...   \n",
       "\n",
       "                                      named_entities  \\\n",
       "0  [Landlord, Friday, 1 month, This morning, 175,...   \n",
       "1                        [Yesterday, about 3pm, n’t]   \n",
       "2                       [Landlord, English, 3 years]   \n",
       "3                                                 []   \n",
       "4  [three, our thirties, every two weeks, a day, ...   \n",
       "\n",
       "                                             summary  \\\n",
       "0  My girlfriend has been renting an apartment wi...   \n",
       "1  Yesterday, my missus and I were freshly post c...   \n",
       "2  We're in a rental we're there is a locked shed...   \n",
       "3  I'm not particularly happy about having my lan...   \n",
       "4  Three males all in their thirties had a flat i...   \n",
       "\n",
       "                                              chunks  \n",
       "0  [Landlord, he, Friday, My girlfriend, an apart...  \n",
       "1  [Advice, vent, landlord invading privacy, my m...  \n",
       "2  [Landlord, property, We, a rental, we, a locke...  \n",
       "3  [Landlords, a local candidate election sign, m...  \n",
       "4  [a Landlord Complain, Beds, I, we, a complaint...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_queries.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>summary</th>\n",
       "      <th>key_terms</th>\n",
       "      <th>named_entities</th>\n",
       "      <th>categories</th>\n",
       "      <th>noun_chunks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The Tribunal orders suppression of the tenants...</td>\n",
       "      <td>['cat', 'door', 'pane', 'glass', 'vacate']</td>\n",
       "      <td>(2023, 4438983, TENANCY TRIBUNAL -, Barfoot &amp; ...</td>\n",
       "      <td>{'Damage': 0.2073230892419815, 'Pet': 0.309160...</td>\n",
       "      <td>['[2023] NZTT 4438983 \\nTENANCY TRIBUNAL', 'Ev...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Landlord applied for compensation followin...</td>\n",
       "      <td>['behind', 'property', 'premise', 'left', 'hel...</td>\n",
       "      <td>(2023, 4392339, 4435900, TENANCY TRIBUNAL - TO...</td>\n",
       "      <td>{'Damage': 0.4811885356903076, 'Pet': 0.193092...</td>\n",
       "      <td>['NZTT', '4435900\\nTENANCY TRIBUNAL - TOKOROA\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>No application for suppression has been made i...</td>\n",
       "      <td>['damage', 'carpet', 'crack', 'vanity', 'ha']</td>\n",
       "      <td>(2023, 4417521, 4406666, TENANCY TRIBUNAL - MA...</td>\n",
       "      <td>{'Damage': 0.9675973057746887, 'Pet': 0.227249...</td>\n",
       "      <td>['[2023] NZTT 4417521, 4406666\\nTENANCY TRIBUN...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The application was filed on 20 March 2023. It...</td>\n",
       "      <td>['rehearing', 'wa', 'application', 'allegation...</td>\n",
       "      <td>(2023, 4534511, TENANCY, TRIBUNAL, Anita Lois ...</td>\n",
       "      <td>{'Damage': 0.15224403142929077, 'Pet': 0.22352...</td>\n",
       "      <td>['[2023] NZTT 4534511 \\nTENANCY TRIBUNAL - \\nA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Nicholas (Nick) Kulavovsky and Natalya Kulakov...</td>\n",
       "      <td>['basement', 'notice', 'quiet', 'retaliatory',...</td>\n",
       "      <td>(2023, 4626454, TENANCY TRIBUNAL -, Nicholas, ...</td>\n",
       "      <td>{'Damage': 0.08154157549142838, 'Pet': 0.40720...</td>\n",
       "      <td>['[2023] NZTT 4626454 \\nTENANCY TRIBUNAL', 'Ev...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             summary  \\\n",
       "0  The Tribunal orders suppression of the tenants...   \n",
       "1  The Landlord applied for compensation followin...   \n",
       "2  No application for suppression has been made i...   \n",
       "3  The application was filed on 20 March 2023. It...   \n",
       "4  Nicholas (Nick) Kulavovsky and Natalya Kulakov...   \n",
       "\n",
       "                                           key_terms  \\\n",
       "0         ['cat', 'door', 'pane', 'glass', 'vacate']   \n",
       "1  ['behind', 'property', 'premise', 'left', 'hel...   \n",
       "2      ['damage', 'carpet', 'crack', 'vanity', 'ha']   \n",
       "3  ['rehearing', 'wa', 'application', 'allegation...   \n",
       "4  ['basement', 'notice', 'quiet', 'retaliatory',...   \n",
       "\n",
       "                                      named_entities  \\\n",
       "0  (2023, 4438983, TENANCY TRIBUNAL -, Barfoot & ...   \n",
       "1  (2023, 4392339, 4435900, TENANCY TRIBUNAL - TO...   \n",
       "2  (2023, 4417521, 4406666, TENANCY TRIBUNAL - MA...   \n",
       "3  (2023, 4534511, TENANCY, TRIBUNAL, Anita Lois ...   \n",
       "4  (2023, 4626454, TENANCY TRIBUNAL -, Nicholas, ...   \n",
       "\n",
       "                                          categories  \\\n",
       "0  {'Damage': 0.2073230892419815, 'Pet': 0.309160...   \n",
       "1  {'Damage': 0.4811885356903076, 'Pet': 0.193092...   \n",
       "2  {'Damage': 0.9675973057746887, 'Pet': 0.227249...   \n",
       "3  {'Damage': 0.15224403142929077, 'Pet': 0.22352...   \n",
       "4  {'Damage': 0.08154157549142838, 'Pet': 0.40720...   \n",
       "\n",
       "                                         noun_chunks  \n",
       "0  ['[2023] NZTT 4438983 \\nTENANCY TRIBUNAL', 'Ev...  \n",
       "1  ['NZTT', '4435900\\nTENANCY TRIBUNAL - TOKOROA\\...  \n",
       "2  ['[2023] NZTT 4417521, 4406666\\nTENANCY TRIBUN...  \n",
       "3  ['[2023] NZTT 4534511 \\nTENANCY TRIBUNAL - \\nA...  \n",
       "4  ['[2023] NZTT 4626454 \\nTENANCY TRIBUNAL', 'Ev...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_orders.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TF-IDF Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the TF-IDF matrix and vectoriser\n",
    "with open(\"models\\\\tfidf\\\\tfidf_matrix.pkl\", \"rb\") as matrix_file:\n",
    "    tfidf_matrix = pickle.load(matrix_file)\n",
    "\n",
    "with open(\"models\\\\tfidf\\\\tfidf_vectorizer.pkl\", \"rb\") as matrix_file:\n",
    "    tfidf_vec = pickle.load(matrix_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get scores for all queries loaded\n",
    "tfidf_scores = []\n",
    "\n",
    "for idx, row in processed_queries.iterrows():\n",
    "    query_tfidf_vector = tfidf_vec.transform([row['query']])\n",
    "    similarities = cosine_similarity(query_tfidf_vector, tfidf_matrix)\n",
    "\n",
    "    tfidf_scores.append(similarities[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Named entity similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load named entity bag of words\n",
    "with open(\"models\\\\ner_bow\\\\ner_bow_model.pkl\", \"rb\") as bow_file:\n",
    "    named_entity_vec = pickle.load(bow_file)\n",
    "\n",
    "with open(\"models\\\\ner_bow\\\\ner_bow_matrix.pkl\", \"rb\") as matrix_file:\n",
    "    named_entity_matrix = pickle.load(matrix_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get scores for all queries loaded\n",
    "ner_scores_temp = []\n",
    "\n",
    "for idx, row in processed_queries.iterrows():\n",
    "    query_ner_vector = named_entity_vec.transform([row['named_entities']])\n",
    "\n",
    "    similarities = cosine_similarity(named_entity_matrix, query_ner_vector)\n",
    "\n",
    "    ner_scores_temp.append(similarities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "ner_scores = []\n",
    "\n",
    "for scores in ner_scores_temp:\n",
    "    ner_scores.append(list(chain(*scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Noun phrase similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load named entity bag of words\n",
    "with open(\"models\\\\nph_bow\\\\nph_bow_model.pkl\", \"rb\") as bow_file:\n",
    "    noun_phrases_vec = pickle.load(bow_file)\n",
    "\n",
    "with open(\"models\\\\nph_bow\\\\nph_bow_matrix.pkl\", \"rb\") as matrix_file:\n",
    "    noun_phrases_matrix = pickle.load(matrix_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get scores for all queries loaded\n",
    "nph_scores_temp = []\n",
    "\n",
    "for idx, row in processed_queries.iterrows():\n",
    "    query_nph_vector = noun_phrases_vec.transform([row['chunks']])\n",
    "\n",
    "    similarities = cosine_similarity(noun_phrases_matrix, query_nph_vector)\n",
    "\n",
    "    nph_scores_temp.append(similarities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "nph_scores = []\n",
    "\n",
    "for scores in nph_scores_temp:\n",
    "    nph_scores.append(list(chain(*scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overall document similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the spaCy model\n",
    "nlp = spacy.load(\"en_core_web_lg\")\n",
    "\n",
    "ovr_scores = []\n",
    "\n",
    "for idx, row in processed_queries.iterrows():\n",
    "    doc1 = nlp(row['summary'])\n",
    "\n",
    "    query_scores = []\n",
    "\n",
    "    for idx, row in processed_orders.iterrows():\n",
    "        doc2 = nlp(row['summary'])\n",
    "\n",
    "        # Calculate similarity\n",
    "        similarity_score = doc1.similarity(doc2)\n",
    "\n",
    "        query_scores.append(similarity_score)\n",
    "\n",
    "    ovr_scores.append(query_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create overall scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Initialize an empty DataFrame with specific columns\n",
    "columns = ['tfidf_scores','named_entity_scores', 'noun_phrase_scores', 'doc_scores']\n",
    "similarity_scores = pd.DataFrame(columns={col: [] for col in columns})\n",
    "\n",
    "similarity_scores['tfidf_scores'] = tfidf_scores\n",
    "similarity_scores['named_entity_scores'] = ner_scores\n",
    "similarity_scores['noun_phrase_scores'] = nph_scores\n",
    "similarity_scores['doc_scores'] = ovr_scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the average similarity score for each document for each query\n",
    "average_list = [sum(x) / len(x) for x in zip(tfidf_scores, ner_scores, nph_scores, ovr_scores)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<class 'list'>, {0: 0.4042127628755586, 1: 0.44531902349295027, 2: 0.4384438380028164, 3: 0.39993470637294626, 4: 0.4031604906992957, 5: 0.3934398061854073, 6: 0.3933938392226194, 7: 0.37528882297625876, 8: 0.37528882297625876, 9: 0.3999447478205628, 10: 0.3962789965879083, 11: 0.4248189858068897, 12: 0.40030366969150116, 13: 0.40030366969150116, 14: 0.36930412644398536, 15: 0.36480160657509986, 16: 0.42642613383239913, 17: 0.4010335830304764, 18: 0.420463128632547, 19: 0.3889240357215349, 20: 0.41169205139472165, 21: 0.4250587777260991, 22: 0.40265870697588263, 23: 0.3981073150103429, 24: 0.4179571714309507, 25: 0.43155041268525696, 26: 0.3405304150102523, 27: 0.32943957939861523, 28: 0.3749881209455881, 29: 0.4079727477633591, 30: 0.3690655754867059, 31: 0.4220223094969383, 32: 0.4002425777101397, 33: 0.4037014423540638, 34: 0.3836518395870482, 35: 0.38011015191049013, 36: 0.37627177911106824, 37: 0.3095816384693444, 38: 0.4001333112832761, 39: 0.4227123282008501, 40: 0.39845044784951167, 41: 0.45026659521615864, 42: 0.4056335812363862, 43: 0.3844251005266781})\n",
      "defaultdict(<class 'list'>, {0: 0.30596946846770623, 1: 0.2996413188017959, 2: 0.2900652073044847, 3: 0.2786029349687973, 4: 0.2819693993382001, 5: 0.25398711899688964, 6: 0.26168278053790534, 7: 0.21453989718505395, 8: 0.21453989718505395, 9: 0.2871182125934055, 10: 0.2600288310876244, 11: 0.29251965967490967, 12: 0.27442469284443993, 13: 0.27442469284443993, 14: 0.23015943705980502, 15: 0.22786780193252032, 16: 0.3029815671526862, 17: 0.2603016659505213, 18: 0.2603669422605054, 19: 0.2652718100496903, 20: 0.2953730493165215, 21: 0.3034897807806326, 22: 0.27608576181495553, 23: 0.282452019514322, 24: 0.2885556052459175, 25: 0.28643909572629567, 26: 0.18896640911524537, 27: 0.18399527493880308, 28: 0.25130236003294193, 29: 0.2731871771915268, 30: 0.22570491361373282, 31: 0.2937697409584666, 32: 0.28256053386147784, 33: 0.28655939322338375, 34: 0.23528992424874082, 35: 0.23511494387956267, 36: 0.23244987786283605, 37: 0.18653529660025142, 38: 0.27647109114320223, 39: 0.2716429674830966, 40: 0.2839730757070883, 41: 0.27492196572514593, 42: 0.2884637277769453, 43: 0.2427635514591488})\n",
      "defaultdict(<class 'list'>, {0: 0.40662939003730075, 1: 0.4867695015690556, 2: 0.44386227247246346, 3: 0.39730379362902046, 4: 0.3829626914398746, 5: 0.3749647255886748, 6: 0.3744030829810576, 7: 0.35122446569784127, 8: 0.35122446569784127, 9: 0.37014198726327474, 10: 0.38478455008638146, 11: 0.39456346640118456, 12: 0.39688279143413774, 13: 0.39688279143413774, 14: 0.33643610088712267, 15: 0.35350363411717234, 16: 0.3760566806354838, 17: 0.4260404528019231, 18: 0.39001645736084706, 19: 0.38419381187718243, 20: 0.3875245403624489, 21: 0.404589597569298, 22: 0.3961190386903166, 23: 0.38400006048703184, 24: 0.3839451182473419, 25: 0.40670227566187256, 26: 0.31838228449349176, 27: 0.3026194388545712, 28: 0.3455311443875003, 29: 0.39741158137885874, 30: 0.3431880756129996, 31: 0.39821479476561816, 32: 0.3846090448091306, 33: 0.395285619664131, 34: 0.35496448399754205, 35: 0.35272538063182557, 36: 0.3470703699954957, 37: 0.2940710507424077, 38: 0.3700260128039795, 39: 0.39080229521220167, 40: 0.36996488604106803, 41: 0.42290466387834413, 42: 0.3873557806601319, 43: 0.377202872069728})\n",
      "defaultdict(<class 'list'>, {0: 0.23057581990535564, 1: 0.24481524588919865, 2: 0.22963335549215202, 3: 0.20579966739804834, 4: 0.1958844080327988, 5: 0.17425724493131112, 6: 0.18120083264126396, 7: 0.12843560914637256, 8: 0.12843560914637256, 9: 0.21866778040985582, 10: 0.17732393031661248, 11: 0.20872638772288554, 12: 0.21167972189452022, 13: 0.21167972189452022, 14: 0.14825883459007258, 15: 0.13430370576953282, 16: 0.20786778285057722, 17: 0.192104534060637, 18: 0.2045392429885321, 19: 0.20336427607380933, 20: 0.23144217385806476, 21: 0.2408865979090512, 22: 0.21694018703200466, 23: 0.19874376352425227, 24: 0.2087792285347409, 25: 0.23817371165836335, 26: 0.12088072779328438, 27: 0.10682877776396951, 28: 0.17293108302554272, 29: 0.19434190631237963, 30: 0.1404051721247499, 31: 0.23685128990521392, 32: 0.2033396796191507, 33: 0.21741451253501257, 34: 0.1495808606282799, 35: 0.15260102406788992, 36: 0.15478600682589772, 37: 0.12257385274562044, 38: 0.2084778873004439, 39: 0.20976933844325513, 40: 0.21138981084964795, 41: 0.21165440991146, 42: 0.1980095758354823, 43: 0.17792736007339202})\n",
      "defaultdict(<class 'list'>, {0: 0.3935779917382375, 1: 0.40787250832366484, 2: 0.4231960797878463, 3: 0.4171929596476829, 4: 0.3981123188162559, 5: 0.41904552650841, 6: 0.38737413083704575, 7: 0.30230284374515315, 8: 0.30230284374515315, 9: 0.43507967296202343, 10: 0.35047322863399305, 11: 0.41784270179220706, 12: 0.3854583109365796, 13: 0.3854583109365796, 14: 0.3385384673639895, 15: 0.3199756619685249, 16: 0.41369992181045045, 17: 0.3990098008856423, 18: 0.39348283978549037, 19: 0.3884790957894328, 20: 0.3916200538400435, 21: 0.4396565048513763, 22: 0.3741767019805003, 23: 0.3791554324151045, 24: 0.40875948974577775, 25: 0.42977826302679234, 26: 0.3295193760955708, 27: 0.30419293168641975, 28: 0.42188286189325974, 29: 0.4304985939429008, 30: 0.34368379560155315, 31: 0.4030209032124177, 32: 0.39729100807114526, 33: 0.43171558079157196, 34: 0.3297710912647233, 35: 0.3532774905693785, 36: 0.36169664672681023, 37: 0.2888167349787914, 38: 0.3712571377824223, 39: 0.3846888830655064, 40: 0.3757211382922402, 41: 0.4432001904740779, 42: 0.37709797160732006, 43: 0.3578762129681211})\n",
      "defaultdict(<class 'list'>, {0: 0.3160926956008561, 1: 0.36495878171315327, 2: 0.3391725504403232, 3: 0.3185529693194184, 4: 0.3169447771868811, 5: 0.32758765280269964, 6: 0.29426242486688764, 7: 0.25299086543592186, 8: 0.25299086543592186, 9: 0.3132199548718225, 10: 0.2918236504614784, 11: 0.3204848575614898, 12: 0.3360075401133158, 13: 0.3360075401133158, 14: 0.27255672369219736, 15: 0.24985620473966, 16: 0.3098825167063961, 17: 0.3355195887272804, 18: 0.31303305497347855, 19: 0.32196893798378656, 20: 0.3285455059850862, 21: 0.3459413082759466, 22: 0.3357393261285465, 23: 0.3371131257362565, 24: 0.3583135582930217, 25: 0.3619742185079495, 26: 0.2539570353851315, 27: 0.22982733006532188, 28: 0.2871909678294352, 29: 0.31186927817863247, 30: 0.2587681016958061, 31: 0.3629395592960454, 32: 0.3260384418438429, 33: 0.3395278930393024, 34: 0.26930162527448726, 35: 0.28106445075331943, 36: 0.2901008881444843, 37: 0.22504868275163428, 38: 0.327243686417862, 39: 0.32943839804752917, 40: 0.31453350650477624, 41: 0.37884951097173036, 42: 0.3133275643941501, 43: 0.29704825831398063})\n"
     ]
    }
   ],
   "source": [
    "# Convert average scores to indexed dictionary\n",
    "averages_scores = []\n",
    "\n",
    "for item in average_list:\n",
    "    averages_dict = defaultdict(list)\n",
    "    for idx, score in enumerate(item):\n",
    "        averages_dict[idx] = score\n",
    "    \n",
    "    averages_scores.append(averages_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the top 3 scoring documents for each query\n",
    "top_3_list = []\n",
    "\n",
    "for idx, scores in enumerate(averages_scores):\n",
    "    sorted_averages = dict(sorted(averages_scores[idx].items(), key=lambda item: item[1], reverse=True))\n",
    "    top_3 = list(sorted_averages.items())[:3]\n",
    "    top_3_list.append(top_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity_scores['top'] = top_3_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tfidf_scores</th>\n",
       "      <th>named_entity_scores</th>\n",
       "      <th>noun_phrase_scores</th>\n",
       "      <th>doc_scores</th>\n",
       "      <th>top</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[0.029248962160740154, 0.04577266659668733, 0....</td>\n",
       "      <td>[0.040893041005476534, 0.17609172895011482, 0....</td>\n",
       "      <td>[0.6969104081344717, 0.7303693904986397, 0.707...</td>\n",
       "      <td>[0.8497986402015459, 0.8290423079263591, 0.892...</td>\n",
       "      <td>[(41, 0.45026659521615864), (1, 0.445319023492...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[0.06036613152238166, 0.04082158363261517, 0.0...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.05890000640537604, 0.0,...</td>\n",
       "      <td>[0.4401997064847175, 0.48741425689320095, 0.44...</td>\n",
       "      <td>[0.7233120358637258, 0.6703294346813675, 0.689...</td>\n",
       "      <td>[(0, 0.30596946846770623), (21, 0.303489780780...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[0.01664921671556973, 0.07491270284312554, 0.0...</td>\n",
       "      <td>[0.08512565307587487, 0.36656416494266014, 0.2...</td>\n",
       "      <td>[0.6613270734036136, 0.672055977898692, 0.6720...</td>\n",
       "      <td>[0.8634156169541448, 0.8335451605917445, 0.846...</td>\n",
       "      <td>[(1, 0.4867695015690556), (2, 0.44386227247246...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[0.04105590691115044, 0.0794356137219548, 0.03...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.22951228504677407, 0.2957947357775568, 0.24...</td>\n",
       "      <td>[0.651735087663498, 0.604030634057283, 0.64031...</td>\n",
       "      <td>[(1, 0.24481524588919865), (21, 0.240886597909...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[0.012794906371000815, 0.04932324559455457, 0....</td>\n",
       "      <td>[0.0, 0.012342857465282813, 0.0972305585328246...</td>\n",
       "      <td>[0.6975133136328191, 0.713315120490142, 0.7140...</td>\n",
       "      <td>[0.8640037469491302, 0.85650880974468, 0.83613...</td>\n",
       "      <td>[(41, 0.4432001904740779), (21, 0.439656504851...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[0.005549984394422312, 0.13879545220356782, 0....</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.009968648060386293, 0.005468...</td>\n",
       "      <td>[0.44268345916331375, 0.5175430446879731, 0.45...</td>\n",
       "      <td>[0.8161373388456884, 0.8034966299610722, 0.860...</td>\n",
       "      <td>[(41, 0.37884951097173036), (1, 0.364958781713...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        tfidf_scores  \\\n",
       "0  [0.029248962160740154, 0.04577266659668733, 0....   \n",
       "1  [0.06036613152238166, 0.04082158363261517, 0.0...   \n",
       "2  [0.01664921671556973, 0.07491270284312554, 0.0...   \n",
       "3  [0.04105590691115044, 0.0794356137219548, 0.03...   \n",
       "4  [0.012794906371000815, 0.04932324559455457, 0....   \n",
       "5  [0.005549984394422312, 0.13879545220356782, 0....   \n",
       "\n",
       "                                 named_entity_scores  \\\n",
       "0  [0.040893041005476534, 0.17609172895011482, 0....   \n",
       "1  [0.0, 0.0, 0.0, 0.0, 0.05890000640537604, 0.0,...   \n",
       "2  [0.08512565307587487, 0.36656416494266014, 0.2...   \n",
       "3  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "4  [0.0, 0.012342857465282813, 0.0972305585328246...   \n",
       "5  [0.0, 0.0, 0.0, 0.009968648060386293, 0.005468...   \n",
       "\n",
       "                                  noun_phrase_scores  \\\n",
       "0  [0.6969104081344717, 0.7303693904986397, 0.707...   \n",
       "1  [0.4401997064847175, 0.48741425689320095, 0.44...   \n",
       "2  [0.6613270734036136, 0.672055977898692, 0.6720...   \n",
       "3  [0.22951228504677407, 0.2957947357775568, 0.24...   \n",
       "4  [0.6975133136328191, 0.713315120490142, 0.7140...   \n",
       "5  [0.44268345916331375, 0.5175430446879731, 0.45...   \n",
       "\n",
       "                                          doc_scores  \\\n",
       "0  [0.8497986402015459, 0.8290423079263591, 0.892...   \n",
       "1  [0.7233120358637258, 0.6703294346813675, 0.689...   \n",
       "2  [0.8634156169541448, 0.8335451605917445, 0.846...   \n",
       "3  [0.651735087663498, 0.604030634057283, 0.64031...   \n",
       "4  [0.8640037469491302, 0.85650880974468, 0.83613...   \n",
       "5  [0.8161373388456884, 0.8034966299610722, 0.860...   \n",
       "\n",
       "                                                 top  \n",
       "0  [(41, 0.45026659521615864), (1, 0.445319023492...  \n",
       "1  [(0, 0.30596946846770623), (21, 0.303489780780...  \n",
       "2  [(1, 0.4867695015690556), (2, 0.44386227247246...  \n",
       "3  [(1, 0.24481524588919865), (21, 0.240886597909...  \n",
       "4  [(41, 0.4432001904740779), (21, 0.439656504851...  \n",
       "5  [(41, 0.37884951097173036), (1, 0.364958781713...  "
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarity_scores"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tenancy_tribunal",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
